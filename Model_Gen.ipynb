{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from __future__ import absolute_import, division, print_function, unicode_literals\n\n#Need to use the latest Tensorflow version - can find it at https://www.tensorflow.org/install/\n#!pip uninstall tensorflow\n#!pip install tensorflow==2.6.0\nimport tensorflow as tf\n##was 2.5.0, now 2.6.0\nimport numpy as np\nimport os\nimport datetime","metadata":{"id":"Rj0WbcOb_ui9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"TensorFlow version: \", tf.__version__)","metadata":{"id":"R_4K1XW6AKOU","outputId":"098476c6-be9b-4c86-8ca1-ce6f2c9c4f90","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())","metadata":{"id":"Y3Y0UcB7ANp5","outputId":"68d9b905-e9b3-4e0a-a89b-228c4e91b04f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\npath = os.getcwd()\nprint(path)","metadata":{"id":"GK3tMP6QAa74","outputId":"e00bb36f-ed27-43f2-900f-652a57aba822","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#If using a directory with multiple files\nimport glob\nimport codecs\nbooks = sorted(glob.glob(path + \"/../input/datatest/cbtest_V_train.txt\"))\nprint(\"Found {} books\".format(len(books)))\n\ntext = \"\"\nfor filename in books:\n    with codecs.open(filename, 'r', 'utf-8') as books:\n        text += books.read()\n\nprint(\"Text is {} characters long\".format(len(text)))","metadata":{"id":"UbljnzZKAiJc","outputId":"67e49ca4-c5f1-4d83-d299-b0fcca1dab76","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#If using a single file\ntext = open(path + '/../input/datatest/cbtest_V_train.txt', 'rb').read().decode(encoding='utf-8')\nprint(\"Text is {} characters long\".format(len(text)))","metadata":{"id":"da0LBD0xAiBC","outputId":"db55c117-1a7f-4ece-8ec6-0694b2d93a32","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words = [w for w in text.split(' ') if w.strip() != '' or w == '\\n']\nprint(\"Text is {} words long\".format(len(words)))","metadata":{"id":"s4tXa2DQAk0h","outputId":"63c7b016-4078-4b1e-8608-fd7434d660cf","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(text[:100])","metadata":{"id":"qoGHsVjhAniK","outputId":"4f518ee8-d51f-4e64-9e8b-281d01bccf93","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Map unique characters to indices\nvocab = sorted(set(text))\nprint ('There are {} unique characters'.format(len(vocab)))\nchar2int = {c:i for i, c in enumerate(vocab)}\nint2char = np.array(vocab)\nprint('Vector:\\n')\nfor char,_ in zip(char2int, range(len(vocab))):\n   print(' {:4s}: {:3d},'.format(repr(char), char2int[char]))","metadata":{"id":"JCsKa9sJAv_1","outputId":"23add00f-4ccd-49af-a217-d27c747f2e4d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_as_int = np.array([char2int[ch] for ch in text], dtype=np.int32)\nprint ('{}\\n mapped to integers:\\n {}'.format(repr(text[:100]), text_as_int[:100]))","metadata":{"id":"EIDZuTwKAwHY","outputId":"47bdbaa8-140f-4f7a-8fd4-355dae5260d0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#tr_text = text_as_int[:14059004] #text separated for training, divisible by the batch size (64)\n#val_text = text_as_int[14059004:] #text separated for validation\n\ntr_text = text_as_int[:25059004]\n#val_text = text_as_int[25059004:35059004]\nval_text = text_as_int[29059004:33059004]","metadata":{"id":"qSg89-GjAwJ3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(text_as_int.shape, tr_text.shape, val_text.shape)","metadata":{"id":"FVEPf30mAwMQ","outputId":"a8ae95d9-0f8c-482a-b8a5-8aa1a8d5b706","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Populate the library of tunables - I like keeping them centralized in case I need to change things around:\nbatch_size = 128\nbuffer_size = 10000\nembedding_dim = 256\nepochs = 25\nseq_length = 200\nexamples_per_epoch = len(text)//seq_length\n#lr = 0.001 #will use default for Adam optimizer\n#rnn_units = 1024\nrnn_units = 1024\nvocab_size = len(vocab)","metadata":{"id":"H-MSYReIAwOW","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr_char_dataset = tf.data.Dataset.from_tensor_slices(tr_text)\nval_char_dataset = tf.data.Dataset.from_tensor_slices(val_text)\nprint(tr_char_dataset, val_char_dataset)\ntr_sequences = tr_char_dataset.batch(seq_length+1, drop_remainder=True)\nval_sequences = val_char_dataset.batch(seq_length+1, drop_remainder=True)\nprint(tr_sequences, val_sequences)\n\nfor item in tr_sequences.take(1):\n    print(repr(''.join(int2char[item.numpy()])))\n    print(item)\nfor item in val_sequences.take(1):\n    print(repr(''.join(int2char[item.numpy()])))\n    print(item)","metadata":{"id":"w3LZlbRwAwQn","outputId":"acd53e4c-2986-47ad-a692-4ea8a4874fda","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def split_input_target(chunk):\n    input_text = chunk[:-1]\n    target_text = chunk[1:]\n    return input_text, target_text\n\ntr_dataset = tr_sequences.map(split_input_target).shuffle(buffer_size).batch(batch_size, drop_remainder=True)\nval_dataset = val_sequences.map(split_input_target).shuffle(buffer_size).batch(batch_size, drop_remainder=True)\nprint(tr_dataset, val_dataset)","metadata":{"id":"en8OT0W0AwTD","outputId":"7b6a13f2-46ad-45bb-ea16-2f3f06dbb019","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n    model = tf.keras.Sequential([\n        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n                              batch_input_shape=[batch_size, None]),\n        tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.LSTM(rnn_units,\n                        return_sequences=True,\n                        stateful=True,\n                        recurrent_initializer='glorot_uniform'),\n        tf.keras.layers.Dropout(0.2), \n        tf.keras.layers.LSTM(rnn_units,\n                        return_sequences=True,\n                        stateful=True,\n                        recurrent_initializer='glorot_uniform'),\n        tf.keras.layers.Dropout(0.2), \n        tf.keras.layers.LSTM(rnn_units,\n                        return_sequences=True,\n                        stateful=True,\n                        recurrent_initializer='glorot_uniform'),\n        tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Dense(vocab_size)\n    ])\n    return model","metadata":{"id":"ERUFnaptAwVb","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_model(\n    vocab_size = len(vocab),\n    embedding_dim=embedding_dim,\n    rnn_units=rnn_units,\n    batch_size=batch_size)","metadata":{"id":"ac4SqLBfAwXz","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for input_example_batch, target_example_batch in tr_dataset.take(1):\n    example_batch_predictions = model(input_example_batch)\n    print(example_batch_predictions.shape, \"respectively: batch_size, sequence_length, vocab_size\")","metadata":{"id":"OWSrjbdmAwaH","outputId":"acd65be0-5a1e-40c0-b086-64c546d37e84","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"id":"24PxYht9Awci","outputId":"e75fc5b3-148a-4b5c-e14d-8dd5321a3bcf","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\nsampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\nprint(\"Input: \\n\", repr(\"\".join(int2char[input_example_batch[0]])))\nprint()\nprint(\"Predictions: \\n\", repr(\"\".join(int2char[sampled_indices ])))","metadata":{"id":"KNTmzN53BB1f","outputId":"aea02af5-cbcc-4dee-c8b9-4c4837043290","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def loss(labels, logits):\n    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\ndef accuracy(labels, logits):\n    return tf.keras.metrics.sparse_categorical_accuracy(labels, logits)\n\nexample_batch_loss  = loss(target_example_batch, example_batch_predictions)\nexample_batch_acc  = accuracy(target_example_batch, example_batch_predictions)\nprint(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\nprint(\"Loss:      \", example_batch_loss.numpy().mean())\nprint(\"Accuracy:      \", example_batch_acc.numpy().mean())","metadata":{"id":"s5luEB7HBB4G","outputId":"9ba25985-cd3d-4753-e45c-135a784797d8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#optimizer = tf.keras.optimizers.Adam() \noptimizer = tf.keras.optimizers.Adam(learning_rate=0.0001) \nmodel.compile(optimizer=optimizer, loss=loss)","metadata":{"id":"wKddgPBnBB8K","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"patience = 3\nearly_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience)","metadata":{"id":"7XrAu4sxBB-Z","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ncheckpoint_dir = './checkpoints'+ datetime.datetime.now().strftime(\"_%Y.%m.%d-%H:%M:%S\")\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n\ncheckpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_prefix,\n    save_weights_only=True)","metadata":{"id":"plDHJsYEBCAs","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nhistory = model.fit(tr_dataset, epochs=epochs, callbacks=[checkpoint_callback, early_stop] , validation_data=val_dataset)\nprint (\"Training stopped as there was no improvement after {} epochs\".format(patience))","metadata":{"id":"cixMRZdABCDX","outputId":"0c19e1c0-c1be-43d4-bf8b-264361ea6ddd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(12,9))\nplt.plot(history.history['loss'], 'g')\nplt.plot(history.history['val_loss'], 'rx') #use if have val data\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train'], loc='upper right')\nplt.legend(['Train', 'Validation'], loc='upper right') #use if have val date\nplt.show()","metadata":{"id":"W9ytPjK8BCF7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.train.latest_checkpoint(checkpoint_dir)","metadata":{"id":"xieJqICSBCIU","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n#model.load_weights('./checkpoints_2019.04.29-00:31:15/ckpt_17')  #if the latest checkpoint is not your preferred\nmodel.load_weights(tf.train.latest_checkpoint(checkpoint_dir))  #if the latest checkpoint is what you want\nmodel.build(tf.TensorShape([1, None]))\nmodel.summary()","metadata":{"id":"b61LAdAgBCK6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_text(model, start_string):\n    \n    print('Generating with seed: \"' + start_string + '\"')\n  \n    num_generate = 10000\n\n    input_eval = [char2int[s] for s in start_string]\n    input_eval = tf.expand_dims(input_eval, 0)\n\n    text_generated = []\n\n    #temperature = 1.0\n    temperature = 0.5\n    model.reset_states()\n    for i in range(num_generate):\n        predictions = model(input_eval)\n        predictions = tf.squeeze(predictions, 0)\n        predictions = predictions / temperature\n        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n        input_eval = tf.expand_dims([predicted_id], 0)\n        text_generated.append(int2char[predicted_id])\n\n    return (start_string + ''.join(text_generated))","metadata":{"id":"_nuCY9y2BCNe","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(r'./fb.h5')\nprint(generate_text(model, start_string=\"fighting for life\"))","metadata":{"id":"JE56pLEWBSJ8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('./sampleTF2.txt', 'w') as f:\n    sampleTF2 = generate_text(model, start_string=\"joy of gods\")\n    f.write(sampleTF2)","metadata":{"id":"Hups_XoCBSL_","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"aShw-2V7BSOP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.save('0.0.h5')","metadata":{"id":"CLGMDL3WbTaJ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(generate_text(model, start_string=\"<sos> death\"))","metadata":{"id":"HuEZ_4qubrZl","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#saves as savedmodel\n#tf.saved_model.save(model, r'/content/drive/MyDrive/Models')","metadata":{"id":"BjVLMaEPmZAr","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model2 = tf.saved_model.load(r'/content/drive/MyDrive/Models')","metadata":{"id":"reFvMYvFdwk6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"SGS5TXMReC86"},"execution_count":null,"outputs":[]}]}